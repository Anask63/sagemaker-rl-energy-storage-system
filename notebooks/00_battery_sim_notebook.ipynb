{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648f7c89",
   "metadata": {},
   "source": [
    "# Energy Storage System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a6f28",
   "metadata": {},
   "source": [
    "In this notebook, we will demontrate how to train an RL agent for Energy Storage System (ESS) arbitrage. \n",
    "\n",
    "The simulated energy environment is created based on the paper [Arbitrage of Energy Storage in Electricity Markets with Deep Reinforcement Learning](https://arxiv.org/abs/1904.12232)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a4960",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "Ensure that you python vitural environment have installed the required python packages in `requirements.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e660461",
   "metadata": {},
   "source": [
    "## Battery Environment Simulator\n",
    "\n",
    "We start by building a energy storage system environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfafa5f5",
   "metadata": {},
   "source": [
    "You need to set `env_config={\"LOCAL\": True}` to use data from local src folder instead of S3.\n",
    "\n",
    "Use full year data: `\"FILEPATH\":\"../refdata/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d422a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List\n",
    "from battery_env_sm import SimpleBattery\n",
    "from nbutils import Report, ReportIO, plot_reward, evaluate_episode, plot_analysis\n",
    "\n",
    "import seaborn as sns    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "env_config = {\"MAX_STEPS_PER_EPISODE\": 168, \"LOCAL\": True, \"FILEPATH\": \"../refdata/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"}\n",
    "\n",
    "EPISODE = 3000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78591a0e",
   "metadata": {},
   "source": [
    "## (0) Random Agent Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d083ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from battery import SimpleBattery\n",
    "\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Random agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, actions: List):\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_action(self, state):\n",
    "        action = np.random.choice([0, 1, 2])\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(1)\n",
    "    env = SimpleBattery(env_config)\n",
    "    agent = SimpleAgent([SimpleBattery.CHARGE, SimpleBattery.DISCHARGE, SimpleBattery.HOLD])\n",
    "    rewards_list = []\n",
    "    history_list: List = []\n",
    "    for i in tqdm(range(EPISODE)):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_rewards += reward\n",
    "            history_list.append([i] + [total_rewards] + [action] + state)\n",
    "            state = next_state\n",
    "\n",
    "        # print(f\"Episode {i+1} ({env.counter}):{total_rewards}\")\n",
    "        rewards_list.append(total_rewards)\n",
    "\n",
    "    average_reward = sum(rewards_list) / len(rewards_list)\n",
    "    print(f\"Average reward: {average_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec7791",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_reward(rewards_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6cc5c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee73880",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The agent action is totally random, regardless of price and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff821a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df_eval = evaluate_episode(agent, env_config)\n",
    "fig = plot_analysis(df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf707ec",
   "metadata": {},
   "source": [
    "## (1) Market price vs cost agent\n",
    "\n",
    "- SELL: when market price is higher than cost\n",
    "- BUY: when market price is lower than cost\n",
    "- HOLD: others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from battery import SimpleBattery\n",
    "\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    What should be the initial initial energy costs?\n",
    "\n",
    "    Buy: electric price < electric cost\n",
    "    Sell: electric price > electric cost\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, actions: List):\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_action(self, state):\n",
    "        electric_price = state[2]\n",
    "        electric_cost = state[1]\n",
    "\n",
    "        if electric_price > electric_cost:\n",
    "            action = SimpleBattery.DISCHARGE\n",
    "        elif electric_price < electric_cost:\n",
    "            action = SimpleBattery.CHARGE\n",
    "        else:\n",
    "            action = SimpleBattery.HOLD\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(1)\n",
    "    env = SimpleBattery(env_config)\n",
    "    agent = SimpleAgent([SimpleBattery.CHARGE, SimpleBattery.DISCHARGE, SimpleBattery.HOLD])\n",
    "    rewards_list = []\n",
    "    history_list: List = []\n",
    "\n",
    "    for i in tqdm(range(EPISODE)):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_rewards += reward\n",
    "            history_list.append([i] + [total_rewards] + [action] + state)\n",
    "            state = next_state\n",
    "\n",
    "        # print(f\"Episode {i+1} ({env.counter}):{total_rewards}\")\n",
    "        rewards_list.append(total_rewards)\n",
    "\n",
    "        \n",
    "    average_reward = sum(rewards_list) / len(rewards_list)\n",
    "    print(f\"Average reward: {average_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_reward(rewards_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209975c",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "    CHARGE = 0\n",
    "    DISCHARGE = 1\n",
    "    HOLD = 2\n",
    "    \n",
    "- Agent discharge (sell:1) when price is higher than cost, and charge (buy:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06498c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df_eval = evaluate_episode(agent, env_config)\n",
    "fig = plot_analysis(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee248cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(\"result_price_vs_cost_agent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c58cf8f",
   "metadata": {},
   "source": [
    "## (2) Market Price vs Historical price Agent\n",
    "\n",
    "- SELL: when market price is higher than past 5 days average price\n",
    "- BUY: when market price is lower than past 5 days average price\n",
    "- HOLD: others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fef3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from battery import SimpleBattery\n",
    "\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Buy: market price < past last x days average price\n",
    "    Sell: market price > past last x days average price\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, actions: List):\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_action(self, state):\n",
    "        market_price = state[2]\n",
    "        past_average_price = sum(state[-5:]) / len(state[-5:])\n",
    "\n",
    "        if market_price > past_average_price:\n",
    "            action = SimpleBattery.DISCHARGE\n",
    "        elif market_price < past_average_price:\n",
    "            action = SimpleBattery.CHARGE\n",
    "        else:\n",
    "            action = SimpleBattery.HOLD\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(1)\n",
    "    env = SimpleBattery(env_config)\n",
    "    agent = SimpleAgent([SimpleBattery.CHARGE, SimpleBattery.DISCHARGE, SimpleBattery.HOLD])\n",
    "    rewards_list = []\n",
    "    history_list: List = []\n",
    "\n",
    "    for i in tqdm(range(EPISODE)):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_rewards += reward\n",
    "            history_list.append([i] + [total_rewards] + [action] + state)\n",
    "            state = next_state\n",
    "\n",
    "        # print(f\"Episode {i+1} ({env.counter}):{total_rewards}\")\n",
    "        rewards_list.append(total_rewards)\n",
    "\n",
    "    average_reward = sum(rewards_list) / len(rewards_list)\n",
    "    print(f\"Average reward: {average_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_reward(rewards_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bbbcff",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "    CHARGE = 0\n",
    "    DISCHARGE = 1\n",
    "    HOLD = 2\n",
    "    \n",
    "- Agent will start selling when market price is increasing (high than last 5 days average), and buy when market price is dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea76c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df_eval = evaluate_episode(agent, env_config)\n",
    "fig = plot_analysis(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(\"result_hist_price_agent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494865a6",
   "metadata": {},
   "source": [
    "## (3) SageMaker RL - DQN\n",
    "\n",
    "Next is to use DQN algorithm running on SageMaker RL. Please refer to separate notebook for more info.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbbbe7-ad5e-4fc8-b6b7-c9ddddd47da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
