{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18cf972",
   "metadata": {},
   "source": [
    "# Energy Storage System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a878355",
   "metadata": {},
   "source": [
    "In this notebook, we will demontrate how to train an RL agent for Energy Storage System (ESS) arbitrage. \n",
    "\n",
    "The simulated energy environment is created based on the paper [Arbitrage of Energy Storage in Electricity Markets with Deep Reinforcement Learning](https://arxiv.org/abs/1904.12232)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ed67b",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "### Python Package\n",
    "Ensure that you python vitural environment have installed the required python packages in `requirements.txt`\n",
    "\n",
    "### Dataset\n",
    "Download dataset from [here](https://aemo.com.au/en/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data) and placed into `data` folder as follows:\n",
    "\n",
    "```\n",
    "|-- data\n",
    "|   `-- PRICE_AND_DEMAND_202105_NSW1.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53249915",
   "metadata": {},
   "source": [
    "## Battery Environment Simulator\n",
    "\n",
    "We start by building a energy storage system environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a36e9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You need to set `env_config={\"LOCAL\": True}` to use data from local src folder instead of S3.\n",
    "\n",
    "Use full year data: `\"FILEPATH\":\"data/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "from battery_env_sm import SimpleBattery\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3fd7fc",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_reward(rewards_list:List):\n",
    "    average_reward = sum(rewards_list) / len(rewards_list)\n",
    "    print(f\"Average reward: {average_reward}\")\n",
    "    plt.figure(figsize=(20,5))\n",
    "    ax = sns.lineplot(data=rewards_list)\n",
    "    ax.set_ylabel('Mean reward per episode', fontsize=20)\n",
    "    ax.set_xlabel('Iteration', fontsize=20)\n",
    "    plt.axhline(y=average_reward, color='r')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_actions(df_history, episode:List =[0,1,2]):\n",
    "    df_temp = df_history[df_history['episode'].isin(episode)]\n",
    "\n",
    "    plt.figure(figsize=(20,5))\n",
    "    sns.lineplot(data=df_temp[['cost','price']])\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.scatterplot(data=df_temp[['action']])\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['energy']])\n",
    "    \n",
    "def plot_analysis(df_history, episode:List=None):\n",
    "    if episode is not None:\n",
    "        df_temp = df_history[df_history['episode'].isin(episode)]\n",
    "    else:\n",
    "        df_temp = df_history\n",
    "\n",
    "    print(f\"Average reward: {df_temp['reward'].sum():.02f}\")\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['cost','price']])\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.scatterplot(data=df_temp[['action']])\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['reward']])\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['total_reward']])\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['energy']])\n",
    "    \n",
    "    \n",
    "def evaluate_episode(agent):\n",
    "    \"\"\"\n",
    "    Run evaluation over a single episode.\n",
    "\n",
    "    Input:\n",
    "        agent: trained agent.\n",
    "    \"\"\"\n",
    "    evaluation_list: List = []\n",
    "    done = False\n",
    "    env_config = {\"MAX_STEPS_PER_EPISODE\": 168, \"LOCAL\": True, \"FILEPATH\": \"data/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"}\n",
    "    env = SimpleBattery(env_config)\n",
    "    state = env.reset()\n",
    "    print(f\"Index: {env.index}\")\n",
    "    total_rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_rewards += reward\n",
    "        evaluation_list.append([reward] + [total_rewards] + [action] + state)\n",
    "        state = next_state\n",
    "\n",
    "    df_cols = [\n",
    "        \"reward\",\n",
    "        \"total_reward\",\n",
    "        \"action\",\n",
    "        \"energy\",\n",
    "        \"cost\",\n",
    "        \"price\",\n",
    "        \"price_t1\",\n",
    "        \"price_t2\",\n",
    "        \"price_t3\",\n",
    "        \"price_t4\",\n",
    "        \"price_t5\",\n",
    "    ]\n",
    "    df_eval = pd.DataFrame(evaluation_list, columns=df_cols)\n",
    "    return df_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e491f5",
   "metadata": {},
   "source": [
    "## (0) Random Agent Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from battery import SimpleBattery\n",
    "\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Random agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, actions: List):\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_action(self, state):\n",
    "        action = np.random.choice([0, 1, 2])\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(1)\n",
    "\n",
    "    env_config = {\"MAX_STEPS_PER_EPISODE\": 168, \"LOCAL\": True, \"FILEPATH\":\"data/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"}\n",
    "    env = SimpleBattery(env_config)\n",
    "    agent = SimpleAgent([SimpleBattery.CHARGE, SimpleBattery.DISCHARGE, SimpleBattery.HOLD])\n",
    "    EPISODE = 100\n",
    "    rewards_list = []\n",
    "    history_list: List = []\n",
    "    for i in tqdm(range(EPISODE)):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_rewards += reward\n",
    "            history_list.append([i] + [total_rewards] + [action] + state)\n",
    "            state = next_state\n",
    "\n",
    "        # print(f\"Episode {i+1} ({env.counter}):{total_rewards}\")\n",
    "        rewards_list.append(total_rewards)\n",
    "\n",
    "    average_reward = sum(rewards_list) / len(rewards_list)\n",
    "    print(f\"Average reward: {average_reward}\")\n",
    "\n",
    "    df_cols = [\n",
    "        \"episode\",\n",
    "        \"total_reward\",\n",
    "        \"action\",\n",
    "        \"energy\",\n",
    "        \"cost\",\n",
    "        \"price\",\n",
    "        \"price_t1\",\n",
    "        \"price_t2\",\n",
    "        \"price_t3\",\n",
    "        \"price_t4\",\n",
    "        \"price_t5\",\n",
    "    ]\n",
    "    df_history = pd.DataFrame(history_list, columns=df_cols)\n",
    "    print(\"df_history\", df_history.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce993f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reward(rewards_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb79bc",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17208ace",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The agent action is totally random, regardless of price and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df_eval = evaluate_episode(agent)\n",
    "plot_analysis(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['reward'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed07c08",
   "metadata": {},
   "source": [
    "## (1) Market price vs cost agent\n",
    "\n",
    "- SELL: when market price is higher than cost\n",
    "- BUY: when market price is lower than cost\n",
    "- HOLD: others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from battery import SimpleBattery\n",
    "\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    What should be the initial initial energy costs?\n",
    "\n",
    "    Buy: electric price < electric cost\n",
    "    Sell: electric price > electric cost\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, actions: List):\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_action(self, state):\n",
    "        electric_price = state[2]\n",
    "        electric_cost = state[1]\n",
    "\n",
    "        if electric_price > electric_cost:\n",
    "            action = SimpleBattery.DISCHARGE\n",
    "        elif electric_price < electric_cost:\n",
    "            action = SimpleBattery.CHARGE\n",
    "        else:\n",
    "            action = SimpleBattery.HOLD\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(1)\n",
    "\n",
    "    env_config = {\"MAX_STEPS_PER_EPISODE\": 168, \"LOCAL\": True, \"FILEPATH\":\"data/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"}\n",
    "    env = SimpleBattery(env_config)\n",
    "    agent = SimpleAgent([SimpleBattery.CHARGE, SimpleBattery.DISCHARGE, SimpleBattery.HOLD])\n",
    "    EPISODE = 100\n",
    "    rewards_list = []\n",
    "    history_list: List = []\n",
    "\n",
    "    for i in tqdm(range(EPISODE)):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_rewards += reward\n",
    "            history_list.append([i] + [total_rewards] + [action] + state)\n",
    "            state = next_state\n",
    "\n",
    "        # print(f\"Episode {i+1} ({env.counter}):{total_rewards}\")\n",
    "        rewards_list.append(total_rewards)\n",
    "\n",
    "        \n",
    "    average_reward = sum(rewards_list) / len(rewards_list)\n",
    "    print(f\"Average reward: {average_reward}\")\n",
    "    \n",
    "    df_cols = [\n",
    "        \"episode\",\n",
    "        \"total_reward\",\n",
    "        \"action\",\n",
    "        \"energy\",\n",
    "        \"cost\",\n",
    "        \"price\",\n",
    "        \"price_t1\",\n",
    "        \"price_t2\",\n",
    "        \"price_t3\",\n",
    "        \"price_t4\",\n",
    "        \"price_t5\",\n",
    "    ]\n",
    "    df_history = pd.DataFrame(history_list, columns=df_cols)\n",
    "    print(\"df_history\", df_history.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc59b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reward(rewards_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ab873",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "    CHARGE = 0\n",
    "    DISCHARGE = 1\n",
    "    HOLD = 2\n",
    "    \n",
    "- Agent discharge (sell:1) when price is higher than cost, and charge (buy:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053794da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df_eval = evaluate_episode(agent)\n",
    "plot_analysis(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['reward'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acffb1",
   "metadata": {},
   "source": [
    "## (2) Market Price vs Historical price Agent\n",
    "\n",
    "- SELL: when market price is higher than past 5 days average price\n",
    "- BUY: when market price is lower than past 5 days average price\n",
    "- HOLD: others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a7d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from battery import SimpleBattery\n",
    "\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Buy: market price < past last x days average price\n",
    "    Sell: market price > past last x days average price\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, actions: List):\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_action(self, state):\n",
    "        market_price = state[2]\n",
    "        past_average_price = sum(state[-5:]) / len(state[-5:])\n",
    "\n",
    "        if market_price > past_average_price:\n",
    "            action = SimpleBattery.DISCHARGE\n",
    "        elif market_price < past_average_price:\n",
    "            action = SimpleBattery.CHARGE\n",
    "        else:\n",
    "            action = SimpleBattery.HOLD\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(1)\n",
    "\n",
    "    env_config = {\"MAX_STEPS_PER_EPISODE\": 168, \"LOCAL\": True, \"FILEPATH\":\"data/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"}\n",
    "    env = SimpleBattery(env_config)\n",
    "    agent = SimpleAgent([SimpleBattery.CHARGE, SimpleBattery.DISCHARGE, SimpleBattery.HOLD])\n",
    "    EPISODE = 100\n",
    "    rewards_list = []\n",
    "    history_list: List = []\n",
    "\n",
    "    for i in tqdm(range(EPISODE)):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_rewards += reward\n",
    "            history_list.append([i] + [total_rewards] + [action] + state)\n",
    "            state = next_state\n",
    "\n",
    "        # print(f\"Episode {i+1} ({env.counter}):{total_rewards}\")\n",
    "        rewards_list.append(total_rewards)\n",
    "\n",
    "    average_reward = sum(rewards_list) / len(rewards_list)\n",
    "    print(f\"Average reward: {average_reward}\")\n",
    "    \n",
    "    df_cols = [\n",
    "        \"episode\",\n",
    "        \"total_reward\",\n",
    "        \"action\",\n",
    "        \"energy\",\n",
    "        \"cost\",\n",
    "        \"price\",\n",
    "        \"price_t1\",\n",
    "        \"price_t2\",\n",
    "        \"price_t3\",\n",
    "        \"price_t4\",\n",
    "        \"price_t5\",\n",
    "    ]\n",
    "    df_history = pd.DataFrame(history_list, columns=df_cols)\n",
    "    print(\"df_history\", df_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09157c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reward(rewards_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b5c28c",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "    CHARGE = 0\n",
    "    DISCHARGE = 1\n",
    "    HOLD = 2\n",
    "    \n",
    "- Agent will start selling when market price is increasing (high than last 5 days average), and buy when market price is dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df_eval = evaluate_episode(agent)\n",
    "plot_analysis(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ba04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['reward'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac8072",
   "metadata": {},
   "source": [
    "## (3) SageMaker RL - DQN\n",
    "\n",
    "Next is to use DQN algorithm running on SageMaker RL. Please refer to separate notebook for more info.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (virtualenv_rl)",
   "language": "python",
   "name": "virtualenv_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
