{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker RL Result Evaluation\n",
    "\n",
    "This notebook is to evaluate training job that has been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"common\")\n",
    "sys.path.append(\"src\")\n",
    "import sagemaker\n",
    "from misc import get_execution_role, wait_for_s3_object\n",
    "import ray\n",
    "from ray.rllib.agents import dqn\n",
    "import gym\n",
    "from battery_env_sm import SimpleBattery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_session = sagemaker.session.Session()\n",
    "s3_bucket = sage_session.default_bucket()  \n",
    "s3_output_path = \"s3://{}/\".format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the job_name completed in notebook 02\n",
    "job_name = \"rl-battery-2021-05-10-09-49-21-387\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Job name: {}\".format(job_name))\n",
    "\n",
    "s3_url = \"s3://{}/{}\".format(s3_bucket,job_name)\n",
    "\n",
    "intermediate_folder_key = \"{}/output/intermediate/\".format(job_name)\n",
    "intermediate_url = \"s3://{}/{}\".format(s3_bucket, intermediate_folder_key)\n",
    "\n",
    "print(\"S3 job path: {}\".format(s3_url))\n",
    "print(\"Intermediate folder path: {}\".format(intermediate_url))\n",
    "    \n",
    "tmp_dir = \"/tmp/{}\".format(job_name)\n",
    "os.system(\"mkdir {}\".format(tmp_dir))\n",
    "print(\"Create local folder {}\".format(tmp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tar_key = \"{}/output/model.tar.gz\".format(job_name)\n",
    "    \n",
    "local_checkpoint_dir = \"{}/model\".format(tmp_dir)\n",
    "\n",
    "wait_for_s3_object(s3_bucket, model_tar_key, tmp_dir, training_job_name=job_name)  \n",
    "\n",
    "if not os.path.isfile(\"{}/model.tar.gz\".format(tmp_dir)):\n",
    "    raise FileNotFoundError(\"File model.tar.gz not found\")\n",
    "    \n",
    "os.system(\"mkdir -p {}\".format(local_checkpoint_dir))\n",
    "os.system(\"tar -xvzf {}/model.tar.gz -C {}\".format(tmp_dir, local_checkpoint_dir))\n",
    "\n",
    "print(\"Checkpoint directory {}\".format(local_checkpoint_dir))\n",
    "\n",
    "checkpoint_path = f\"{local_checkpoint_dir}/checkpoint\"\n",
    "print(\"checkpoint_path\",checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents import dqn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def get_agent(checkpoint_path):\n",
    "    def register_env_creator(env_name):\n",
    "        tune.register_env(env_name, lambda env_config: SimpleBattery(env_config))\n",
    "\n",
    "    # Alternatively to register custom env and pass to trainer, DQNTrainer(config=config, env=env_class)\n",
    "    # env_class = \"battery\"\n",
    "    # register_env_creator(env_class)\n",
    "\n",
    "    config = dqn.DEFAULT_CONFIG.copy()\n",
    "    config[\"num_workers\"] = 1\n",
    "    config[\"explore\"] = False\n",
    "    config[\"evaluation_config\"] = {\"explore\": False}\n",
    "\n",
    "    ray.shutdown()\n",
    "    ray.init(local_mode=True)\n",
    "\n",
    "    # Instantiate agent. Agent need env to be registered as it will be using tune behind the scene.\n",
    "    # env: can pass in MyEnv(gym), or a registered environment (e.g. env_class)\n",
    "    agent = dqn.DQNTrainer(config=config, env=SimpleBattery)\n",
    "    # Load trained model\n",
    "    agent.restore(checkpoint_path)\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "def evaluate_episode(agent):\n",
    "    \"\"\"\n",
    "    Run evaluation over a single episode.\n",
    "\n",
    "    Input:\n",
    "        agent: trained agent.\n",
    "    \"\"\"\n",
    "    evaluation_list: List = []\n",
    "    done = False\n",
    "    env_config = {\"MAX_STEPS_PER_EPISODE\": 168, \"LOCAL\": True, \"FILEPATH\": \"data/PRICE_AND_DEMAND_2020FULL_NSW1.csv\"}\n",
    "    env = SimpleBattery(env_config)\n",
    "    state = env.reset()\n",
    "    print(f\"Index: {env.index}\")\n",
    "    total_rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.compute_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_rewards += reward\n",
    "        evaluation_list.append([reward] + [total_rewards] + [action] + state)\n",
    "        state = next_state\n",
    "\n",
    "    df_cols = [\n",
    "        \"reward\",\n",
    "        \"total_reward\",\n",
    "        \"action\",\n",
    "        \"energy\",\n",
    "        \"cost\",\n",
    "        \"price\",\n",
    "        \"price_t1\",\n",
    "        \"price_t2\",\n",
    "        \"price_t3\",\n",
    "        \"price_t4\",\n",
    "        \"price_t5\",\n",
    "    ]\n",
    "    df_eval = pd.DataFrame(evaluation_list, columns=df_cols)\n",
    "    return df_eval\n",
    "\n",
    "\n",
    "def plot_analysis(df_history, episode:List=None):\n",
    "    if episode is not None:\n",
    "        df_temp = df_history[df_history['episode'].isin(episode)]\n",
    "    else:\n",
    "        df_temp = df_history\n",
    "\n",
    "    print(f\"Average reward: {df_temp['reward'].sum():.02f}\")\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['cost','price']])\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.scatterplot(data=df_temp[['action']])\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['reward']])\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['total_reward']])\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    sns.lineplot(data=df_temp[['energy']])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "df_eval = evaluate_episode(agent)\n",
    "plot_analysis(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (virtualenv_rl)",
   "language": "python",
   "name": "virtualenv_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
